\chapter{Image-Based Meshing}
\label{chap:3}

\textit{Image-based meshing} is the process of generating explicitly defined volume meshes from imaging data for the purposes of visualization or scientific computing. The discussion will focus on generating meshes specifically from segmented image data. The term \textit{explicit} refers to defining the mesh in terms of vertex coordinates, polytopes, and the connectivity of those polytopes, as opposed to an \textit{implicit} definition in which the surface is defined as the zero-set of a 4D \textit{indicator function}. The image-based meshing process is typically separated into two major steps - 1) \textit{surface generation} and 2) \textit{CAD-based mesh generation}. Surface generation (also known as \textit{surface extraction}) is a matter of generating a watertight, manifold, polygonized surface mesh or computer-aided design (CAD) model from an image mask. CAD-based mesh generation is the task of generating a volume discretization based on the enclosing polygonized surface. In the spirit of seeking an automated workflow, user interaction is sought to be limited to specifying a target mesh density, and possibly spatial variation.

Surface meshes may also be referred to as \textit{boundary representations (b-reps)}. The term \textit{b-rep} can be used more generally though to refer to any type of surface representation, including \textit{non-uniform rational basis splines (NURBS)}, which is not typically the end goal of surface generation. \textit{Watertight} is the property of a surface mesh being closed - namely, if the surface were filled with water, none of it would leak out. \textit{Manifold} refers to the property of a surface being mappable to a two-dimensional plane. A non-manifold surface in practice amounts to the unintentional existence or absence of surface polytopes and/or their connectivities. It is noted that multi-material interfaces result in non-manifold surfaces at junctions of three or more materials, but the requirement that hanging nodes and self-intersecting faces are not allowed still exists in those cases.

In this chapter, image-based meshing approaches in the literature are surveyed, and a novel image-based meshing approach for binary masks is described. Specifically, a novel surface generation technique is introduced, along with its interaction with existing CAD-based meshing tools. A free image-based meshing tool that has been developed is also introduced.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Image-Based Meshing Approaches}
\label{Image-Based Meshing Approaches}

A number of approaches have been pursued to tackle image-based meshing, most of which are extensions of the highly popular \textit{marching cubes} algorithm~\cite{lorensen_1987}. It assumes an implicit \textit{isosurface} exists whose associated volume is the union of voxels in an image mask that have been assigned the same region. The algorithm considers the center points of voxels in the image to be the vertices of a lattice that intersects the isosurface within each grid cell. Each vertex is assigned a region number based on its associated voxel. The edges that contain an interface are bisected, and those intersections are used to form a triangular patch to approximate the interface within each cell. When making use of symmetries, there are 15 predefined ways in which the isosurface can intersect a grid cell, which are stored in a look-up table. The combination of triangular patches from each grid cell form a continuous surface that is guaranteed closed and manifold~\cite{young_2008}.

The two most glaring limitations of the marching cubes algorithm are that 1) the resulting surfaces exhibit aliasing artifacts that poorly capture smooth and sharp features alike, and 2) the algorithm is limited to surface generation from binary masks (i.e., it cannot generate surfaces for multiple-material masks). Advances in the field of image-based meshing have mostly focused on making improvements to those two limitations - namely, generating smooth surfaces that represent the original object accurately while preserving sharp features; and generating quality surface meshes even for the case of multi-material image masks. The novel work presented in this chapter focuses on the former of those two limitations.

Updegrove \textit{et al.}~\cite{updegrove_2016} use a \textit{lofting} technique on a series of 2D segmentations to generate models of blood vessels. An approximate centerline must be drawn, and 2D segmentations are combined using spline interpolating functions to generate surfaces. Unstructured tetrahedral meshes are then generated from the surfaces. Lofting is known as a 2.5D approach, in that it cannot capture arbitrary topologies. The approach often suffers from significant loss of accuracy; the interpolating splines typically require manual selection of control points; and ambiguities can occur when stacking contours of neighboring slices~\cite{young_2008}. Treating an image mask as a series of 2D masks was a popular approach in past decades, but most modern approaches treat an image mask as a single three-dimensional object to avoid the drawbacks of lofting techniques.

Young \textit{et al.}~\cite{young_2008} use a \textit{direct meshing} approach to generate meshes from multi-material image masks without the intermediate step of creating a surface mesh. The software developed by the authors - \textit{Simpleware} - is regarded among the state-of-the-art in image-based meshing tools. Young \textit{et al.} combine the surface generation and mesh generation stages into one process via their \textit{enhanced volumetric marching cubes} approach. Standard \textit{volumetric marching cubes} generates tetrahedral volumes based on the intersection of the isosurface with grid cells, rather than just triangular surface patches as is done in conventional marching cubes. The authors extended the volumetric algorithm to handle the intersection of up to eight regions in one grid cell - the maximum number of intersections that can occur for a Cartesian grid. The number of entries in the look-up table increases accordingly to 70. The resulting mesh is \textit{mixed hex-tet}, in that tetrahedra exist near the surface based on the extended volumetric marching cubes approach, internal voxels are converted directly to hexahedra, and pyramidal and tetrahedral elements exist in the transitional layer in between. Additional efforts to reduce the mesh size are made by converting surface tetrahedra to hexahedra where appropriate, and by performing an octree-based approach to collect neighboring interior hexahedral elements into larger elements. Nonetheless, this \textit{grid-based} approach results in a surface mesh that is very fine, which subsequently constrains the size of interior elements in the volume mesh. Practically speaking, the resulting mesh from this approach yields an intractably large number of degrees of freedom for simulation purposes. Thus, the number of points and polyhedra to define the surface must be reduced, a process known as \textit{decimation}. In turn, this allows the volumetric discretization to be coarser as well.

Indeed, the default and recommended approach in \textit{Simpleware} (known as \textit{+FE Free}) is to follow the same paradigm that has been outlined at the beginning of this chapter. Namely, the software generates a surface using extended marching cubes, performs multi-part decimation and smoothing~\cite{egst}, and finally uses a conventional CAD-based tetrahedral mesher to generate fully tetrahedral meshes from the polygonized surfaces.

Meyer \textit{et al.}~\cite{meyer_2008} employ a \textit{particle-based sampling} technique for multi-material volumes. Surface samples (called \textit{particles}) are constrained to the zero-set of an implicit function. The distance between particles are locally adapted to create higher densities of points near surface features. A Delaunay tetrahedralization of the sampling points is computed, each tetrahedron is assigned a material label, and the surface mesh is generated by extracting the faces bounded by tetrahedra with different material labels. Finally, a conventional CAD-based tetrahedral mesher is once again employed to produce an analysis-ready mesh. The approach faithfully and robustly captures the geometries of complex material interfaces, but has debilitating performance issues, even by the own admission of the authors.

A number of other techniques have been published on the topic of image-based meshing, often times coming from completely different perspectives on the problem~\cite{bronson_2014,fang_2009,boissonnat_2009,zhao_2016}. Although several of the works presented here and otherwise attempt to generate surfaces for multi-material image masks, a great deal of effort and applicability still exists for generating high quality surfaces (and resulting meshes) from binary image masks. This will be the focus of the remainder of this chapter.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Surface Generation}
\label{Surface Generation}

The most straightforward approach to extracting the surface from a binary image mask is simply applying the marching cubes algorithm. As alluded to in the previous section, though, surfaces generated by the marching cubes algorithm are inadequate for any simulation problem. Specifically, surfaces of this kind exhibit a ``Lego-like'' appearance to them that is visually displeasing, does not represent the original object being scanned, and makes the resulting surface unacceptable for any simulation involving contact. Thus, the surface must be smoothed, ideally using a technique that attempts to preserve the volume of the original object such as \textit{HC Laplacian smoothing}~\cite{vollmer_1999} or \textit{Taubin smoothing}~\cite{taubin_1995}. Nonetheless, the step-like appearance of surfaces extracted by marching cubes often requires a degree of smoothing that causes a significant loss in features of the desired surface, and/or the surface to become non-manifold. Sophisticated surface generation techniques attempt to generate a surface that preserves both the smooth and sharp features of the original object surface.

Labsik \textit{et al.}~\cite{labsik_2002} extract a coarse resolution surface using marching cubes, followed by iteratively remeshing to finer resolutions where features exist. Kobbelt \textit{et al.}~\cite{kobbelt_2001} retain sharp features from binary image masks by modifying the marching cubes algorithm in two ways: by enhancing the discrete distance field that defines the underlying isosurface of the image mask, and by adding additional sample points to detect edges and corners. Depending on the application, though, surface smoothness can just as well be the highest priority when extracting the surface. Lempitsky~\cite{lempitsky_2010}, for example, modifies the isosurface function and solves a convex quadratic optimization problem for each grid cell to enforce higher-order smoothness.

The approach outlined herein involves generating a high-quality point cloud that approximates the interface, followed by a  \textit{surface reconstruction} technique based on Voronoi partitioning. Surface reconstruction here is the process of generating watertight, explicit, manifold surfaces from \textit{point cloud} data. The approach attempts to create smooth surfaces without over-smoothing, and has the hooks in place to capture sharp features as well.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Point Cloud Generation}
\label{Point Cloud Generation}

Given a segmented image, we seek to generate an \textit{oriented point cloud} to approximate the surface of the object of interest. A point cloud is oriented if the surface normal data is included at each point in addition to spatial coordinates. To compute the point cloud, the image mask is sampled with overlapping \textit{windows} to locally approximate material interfaces. For each three-dimensional window, the following tasks are performed:
\begin{itemize}[noitemsep]
  \item Determine whether the window involves an interface
  \item Approximate the interface via functional minimization
  \item Place point and associated normal based on the approximated interface
\end{itemize}
The basic sequence is shown in 2D in panels (a-c) of~\figref{vor}. Each step will be described in turn.

\begin{figure}[ht]
\centering
\subfigure[]{%
		\includegraphics[scale=0.57]{media/2-shabaka/1-vor/dem1.png}
\label{fig:vor1}}
\subfigure[]{%
		\includegraphics[scale=0.57]{media/2-shabaka/1-vor/dem2.png}
\label{fig:vor2}}
\subfigure[]{%
		\includegraphics[scale=0.57]{media/2-shabaka/1-vor/dem3.png}
\label{fig:vor3}}
\subfigure[]{%
		\includegraphics[scale=0.57]{media/2-shabaka/1-vor/dem4.png}
\label{fig:vor4}}
%
\caption{(a) Sampling window of segmented image, (b) interface approximation, (c) point/normal placement, and d) Voronoi site placement. Green voxels belong to the material of interest \textit{m} and blue voxels are void. }
\label{fig:vor}
\end{figure}

\subsubsection{Window Selection}

Define the set of all voxels in a segmented image as $\mathcal{I}$. The segmented image  $\mathcal{I}$ is sampled with overlapping windows, each of which is a voxelized sphere with voxel radius $R_{\mathcal{W}}$. The sampling distance between adjacent windows is $d_{\mathcal{W}}$. The set of voxels in a particular window is defined as $\mathcal{W}$, and the number of voxels in that window is $n_{\mathcal{W}}$. Define the set of voxels in $\mathcal{W}$ that belong to material $m$ to be $\mathcal{M}$, and the number of voxels in $\mathcal{M}$ to be $n_{\mathcal{M}}$. A window $\mathcal{W}$ is deemed acceptable if it satisfies a threshold requirement. Define $k_{\mathcal{M}}$ as the ratio of voxels in $\mathcal{M}$ to the voxels in $\mathcal{W}$, i.e., $k_{\mathcal{M}} = n_{\mathcal{M}}/n_{\mathcal{W}}$. For a threshold value $\overline{k}_{\mathcal{M}}$, the window is discarded if $k_{\mathcal{M}} > \overline{k}_{\mathcal{M}}$ or $k_{\mathcal{M}} < 1 - \overline{k}_{\mathcal{M}}$. Thus, further calculations are only performed if there are enough voxels of both material \textit{m} and of void to justify approximating a material interface. Refer to~\tabref{window} for a list of these variables and their descriptions. 

\begin{table}[htbp!]
 \centering
   \begin{tabular}{|c||c|}
   \hline
   {\textbf{Variable}} & \textbf{Description} \\ \hline \hline
   $\mathcal{I}$ & set of all voxels in a segmented image \\ \hline
   $\mathcal{W}$ & set of all voxels in a window \\ \hline
   $m$ & material of interest \\ \hline
   {$k_{\mathcal{M}}$} & ratio of voxels in $\mathcal{M}$ to voxels in $\mathcal{W}$\\ \hline
   {$\overline{k}_{\mathcal{M}}$ \rule{0mm}{4mm}} & threshold value for $k_{\mathcal{M}}$ \\ \hline 
   $R_{\mathcal{W}}$ & window radius (in voxels) \\ \hline
   $d_{\mathcal{W}}$ & sampling distance between adjacent windows (in voxels) \\ \hline  
\end{tabular}
\caption{List of variables for window selection}
\label{tab:window}
\end{table}

\subsubsection{Interface Approximation}

For a particular window $\mathcal{W}$, we seek to approximate the interface between voxels belonging to $\mathcal{M}$ and voxels belonging to $\mathcal{W} \setminus \mathcal{M}$ by a surface $\mathcal{S}$. Assuming $\mathcal{W}$ has been deemed acceptable, an approximating sphere $\mathcal{D}$ of radius $R$ is defined, such that the center and volume of this sphere equal the center and volume of the window $\mathcal{W}$, respectively.

Define $\Omega_p$ as the physical space covered by the voxels belonging to $\mathcal{M}$. Define $\Omega$ as the physical space covered by an approximating lens to $\Omega_p$, determined by the space enclosed by $\mathcal{D}$ and $\mathcal{S}$. The surface $\mathcal{S}$ is determined by minimizing the error in certain geometric properties between $\Omega$ and $\Omega_p$~(see~\figref{figure3}).

\begin{figure}[ht]
\centering
\subfigure[Window $\mathcal{W}$]{%
		\includegraphics[scale=0.72]{media/om/dem2.pdf}
\label{fig:subfigure2}}
\subfigure[Approximating sphere $\mathcal{D}$]{%
		\includegraphics[scale=0.72]{media/om/dem3.pdf}
\label{fig:subfigure3}}

\subfigure[Approximating surface $\mathcal{S}$]{%
		\includegraphics[scale=0.72]{media/om/dem4.pdf}
\label{fig:subfigure4}}
\subfigure[voxelized region $\Omega_p$]{%
		\includegraphics[scale=0.72]{media/om/omp.pdf}
\label{fig:subfigure5}}
\subfigure[Approximating lens $\Omega$]{%
		\includegraphics[scale=0.72]{media/om/om.pdf}
\label{fig:subfigure6}}

\caption{Interface approximation demonstrated in 2D}
\label{fig:figure3}
\end{figure}

The open surface $\mathcal{S}$ that approximates the interface takes an assumed form - for these purposes the interface is assumed to be a plane. If the center of the window is defined to be the origin, the planar interface takes the form $x' = d$, where $(x',y',z')$ are in a transformed coordinate system and $d$ is the perpendicular distance from the origin to the plane~(see~\figref{quad}).

\begin{figure}[ht!]
	\centering
		\includegraphics[scale=0.3]{media/om/window.pdf}
	\caption{Plane interface approximation demonstrated in 2D}
	\label{fig:quad}
\end{figure}

Define the following moments of volume for $\Omega_p$:
\begin{alignat}{5}
&{} &&V^p = \int_{\Omega_p}dv &&{} \\
I_{x\phantom{z}}^p &= \int_{\Omega_p}xdv, &&I_{y\phantom{z}}^p = \int_{\Omega_p}ydv, &&I_{z\phantom{z}}^p = \int_{\Omega_p}zdv \\
I^p_{xy} &= \int_{\Omega_p}xydv, &&I^p_{xz} = \int_{\Omega_p}xzdv, &&I^p_{yz} = \int_{\Omega_p}yzdv \\
I^p_{xx} &= \int_{\Omega_p}(y^2 + z^2)dv, \text{\ \ \ \ \ \ }&&I^p_{yy} = \int_{\Omega_p}(x^2 + z^2)dv, \text{\ \ \ \ \ \ }&&I^p_{zz} = \int_{\Omega_p}(x^2 + y^2)dv
\end{alignat}
And similarly for $\Omega$:
\begin{alignat}{5}
&{} &&V = \int_{\Omega}dv &&{} \\
I_{x\phantom{z}} &= \int_{\Omega}xdv, &&I_{y\phantom{z}} = \int_{\Omega}ydv, &&I_{z\phantom{z}} = \int_{\Omega}zdv \\
I_{xy} &= \int_{\Omega}xydv, &&I_{xz} = \int_{\Omega}xzdv, &&I_{yz} = \int_{\Omega}yzdv \\
I_{xx} &= \int_{\Omega}(y^2 + z^2)dv, \text{\ \ \ \ \ \ }&&I_{yy} = \int_{\Omega}(x^2 + z^2)dv, \text{\ \ \ \ \ \ }&&I_{zz} = \int_{\Omega}(x^2 + y^2)dv
\end{alignat}
For the purposes of computing an error functional, define the following quantities:
\begin{alignat}{3}
f^p &= V^p, \text{\ \ \ \ \ }&&f(d,\psi,\theta) = V \\
\bm{g}^p &= \left[\begin{array} {ccc} {I_x^p} \\ {I_y^p} \\ {I_z^p} \end{array} \right], \text{\ \ \ \ \ }&&\bm{g}(d,\psi,\theta) = \left[\begin{array} {ccc} {I_x} \\ {I_y} \\ {I_z} \end{array} \right] \\
\bm{h}^p &= \left[\begin{array} {ccc} {I_{xx}^p} & {-I_{xy}^p} & {-I_{xz}^p}\\ {-I_{xy}^p} & {I_{yy}^p} & {-I_{yz}^p} \\ -{I_{xz}^p} & {-I_{yz}^p} & {I_{zz}^p} \end{array} \right],\text{\ \ \ \ \ \ \ }&&\bm{h}(d,\psi,\theta) = \left[\begin{array} {ccc} {I_{xx}} & {-I_{xy}} & {-I_{xz}}\\ {-I_{xy}} & {I_{yy}} & {-I_{yz}} \\ -{I_{xz}} & {-I_{yz}} & {I_{zz}} \end{array} \right]
\end{alignat}
Define the relative errors as:
\begin{align}
e_0(d,\psi,\theta) &=  \sqrt{\frac{(f - f^p)^2}{(f^p)^2}} \\
e_1(d,\psi,\theta) &=  \sqrt{\frac{(g_i - g_i^p)(g_i - g_i^p)}{g_i^{p}g_i^{p}}} \\
e_2(d,\psi,\theta) &=  \sqrt{\frac{(h_{ij} - h_{ij}^p)(h_{ij} - h_{ij}^p)}{h_{ij}^{p}h_{ij}^{p}}}
\end{align}
Finally, we define the relative error functional as follows:
\begin{align}
\mathcal{F}(d,\psi,\theta) = \beta_0e_0 + \beta_1e_1 + \beta_2e_2
\end{align}
where $e_0$, $e_1$, and $e_2$ are relative errors between the zeroth, first, and second order moments of volume of $\Omega_p$ and $\Omega$, respectively. They are functions of the interface parameters $d$, $\psi$, and $\theta$, where $\psi$ and $\theta$ are the yaw and pitch angles defining the plane. The values $\beta_0$, $\beta_1$, and $\beta_2$ are weighting coefficients, where $\beta_2 = 1 - \beta_0 - \beta_1$, and $\beta_i \in [0, 1]$. We seek the solution to the following unconstrained minimization problem: $\displaystyle \min_{d, \psi, \theta} \mathcal{F}(d,\psi,\theta)$, which can be solved by a variety of well-established techniques.

The moments of volume of $\Omega_p$ are computed based on a straightforward use of voxel dimensions and the parallel axis theorem. Those of $\Omega$, on the other hand, are computed based on an intricate dependence on $d$, $\psi$, and $\theta$:

\begin{align}
p &= \sqrt{R^2 - d^2} \\
V^* &= 2\pi\left[-\frac{1}{2}dp^2 + \frac{1}{3}R^3 - \frac{1}{3}(R^2 - p^2)^{3/2} \right] \\
I^*_{x'x'} &= \frac{\pi}{30}\left[-15dp^4 + \sqrt{R^2-p^2}\left(12p^4 - 4p^2R^2 - 8R^4\right) + 8R^5 \right] \\
\begin{split}
I^*_{y'y'} &= \frac{\pi}{480}\Big[-160d^3p^2 + 128R^5 - \sqrt{R^2-p^2}\left(128R^4 - 96p^2R^2 - 32p^4\right) - 120dp^4 \Big]
\end{split}
\end{align}
\begin{align}
V &=  \begin{cases}
      V^*, & \text{if}\ d \geq 0 \\
      V^* + \frac{4\pi}{3}\left(R^2-p^2\right)^{3/2}, & \text{otherwise}
    \end{cases} \\
I_{x'} &= \frac{\pi}{4}\left[2p^2(R^2-d^2) - p^4 \right]\\
I_{y'} &= I_{z'} = 0 \\
I_{x'y'} &= I_{x'z'} = I_{y'z'} = 0 \\
I_{x'x'} &=  \begin{cases}
      I^*_{x'x'}, & \text{if}\ d \geq 0 \\
       I^*_{x'x'} + \frac{4\pi}{15}(R^2-p^2)^{3/2}(3p^2+2R^2), & \text{otherwise}
    \end{cases} \\
I_{y'y'} &=  \begin{cases}
     I^*_{y'y'}, & \text{if}\ d \geq 0 \\
     I^*_{y'y'} + \frac{2\pi}{15}(R^2-p^2)^{3/2}(p^2+4R^2), & \text{otherwise}
    \end{cases} \\
I_{z'z'} &= I_{y'y'}
\end{align}

Unsurprisingly, certain moments of volume exhibit symmetries in regard to the $y'$ and $z'$ axes. Note that additional terms may exist if $d$ is negative. The geometric quantities are computed in the transformed coordinate frame, and then transformed back to the original desired coordinate frame. This rotation is not the same for zeroth, first, and second moments due to the different tensor rank for each of these quantities. Once transformed, the moments of $\Omega$ and $\Omega_p$, both in the original coordinate frame, are compared. There is of course no transformation needed in comparing the zeroth moment of volume. The first and second moments are transformed in the following manner:

\begin{align}
\bm{R} &= \left[\begin{array} {ccc} {\cos\psi\cos\theta} & {-\sin\psi} & {\cos\psi\sin\theta}\\ {\sin\psi\cos\theta} & {\cos\psi} & {\sin\psi\sin\theta} \\
{-\sin\theta} & {0} & {\cos\theta}\end{array} \right] \\
\left[\begin{array} {ccc} {I_x} \\ {I_y} \\ {I_z} \end{array} \right] &= \bm{R} \left[\begin{array} {ccc} {I_{x'}} \\ {I_{y'}} \\ {I_{z'}} \end{array} \right]\\
\bm{I}' &= \left[\begin{array} {ccc} {I_{x'x'}} & {-I_{x'y'}} & {-I_{x'z'}}\\ {-I_{x'y'}} & {I_{y'y'}} & {-I_{y'z'}} \\ -{I_{x'z'}} & {-I_{y'z'}} & {I_{z'z'}} \end{array} \right] \\
\bm{I} &= \bm{R}\bm{I}'\mathbf{R}^T = \left[\begin{array} {ccc} {I_{xx}} & {-I_{xy}} & {-I_{xz}}\\ {-I_{xy}} & {I_{yy}} & {-I_{yz}} \\ -{I_{xz}} & {-I_{yz}} & {I_{zz}} \end{array} \right]
\end{align}

With all relevant quantities defined, the subplex search method~\cite{rowan} is used to minimize the error functional using an implementation in the package \textit{NLopt}~\cite{nlo}. The method is a \textit{derivative-free} method that is well suited for optimizing objective functions that are noisy or discontinuous. It was selected as the optimization approach due to the existence of square roots in the objective function, and the fact that robustness to a variety of inputs was the highest priority in developing the algorithm. The performance of the point generation algorithm was not sacrificed as a result of the choice. A convergence tolerance $\varepsilon$ is defined such that on successive iterations, $\left| \mathcal{F}_{i+1} - \mathcal{F}_{i}\right| < \epsilon$, where the subscript corresponds to the iteration number. Additionally, the solution is only accepted if the error functional is below a specified value $\overline{\mathcal{F}}$, that is, $\Omega$ approximates $\Omega_p$ to a satisfactory degree. Specifically, we require that once convergence has been satisfied, the criterion $\mathcal{F} < \overline{\mathcal{F}}$ must also be met for the point and normal to be retained. In this way, outliers in which the error minimization performs poorly are discarded. This typically occurs in regions of high curvature, where a plane does not approximate such an interface well. The point cloud is dense enough that simply discarding these points does not cause under-sampling of the surface.

The solution to the minimization problem yields the values $d$, $\psi$, and $\theta$ that determine the optimal surface $\mathcal{S}$, from which the interface point and normal are defined. Refer to~\tabref{surface} for a summary of variables used in approximating the interface.

\begin{table}[htbp!]
 \centering
   \begin{tabular}{|c||c|}
   \hline
   {\textbf{Variable}} & {\textbf{Description}} \\ \hline \hline
   $\mathcal{D}$ & approximating sphere to $\mathcal{W}$ \\ \hline
   $\mathcal{S}$ & approximating surface to interface of interest \\ \hline      
   $R$ & radius of $\mathcal{D}$ \\ \hline   
   $\Omega_p$ & physical space covered by voxels belonging to $\mathcal{W}$ \\ \hline
   $\Omega$ & physical space covered by approximating lens of $\Omega_p$ \\ \hline      
   $(x,y,z)$ & axes aligned with image scan, whose origin is at the center of $\mathcal{W}$\\ \hline
   \multirow{2}{*}{$(x',y',z')$} & orthogonal axes whose origin is at the center of window $\mathcal{W}$,\\
   {} & where $x'$ passes through the centroid of $\Omega$ \\ \hline   
   $d$ & perpendicular distance from center of $\mathcal{D}$ to plane $\mathcal{S}$  \\ \hline
   $\psi$ & yaw angle of rotation between $(x,y,z)$ and $(x',y',z')$ axes \\ \hline   
   $\theta$ & pitch angle of rotation between $(x,y,z)$ and $(x',y',z')$ axes \\ \hline
   $V^p$ & volume of $\Omega_p$ \\ \hline
   $I_{x}^p, I_y^p$ & first moments of volume of $\Omega_p$ \\ \hline     
   $I_{xy}^p, I_{xz}^p, I_{yz}^p$ & products of volume of $\Omega_p$ \\ \hline      
   $I_{xx}^p, I_{xy}^p, I_{yy}^p$ & second moments of volume of $\Omega_p$ \\ \hline
   $V$ & volume of $\Omega$ \\ \hline
   $I_{x}, I_y$ & first moments of volume of $\Omega$ \\ \hline
   $I_{xy}, I_{xz}, I_{yz}$ & products of volume of $\Omega$ \\ \hline   
   $I_{xx}, I_{xy}, I_{yy}$ & second moments of volume of $\Omega$ \\ \hline
   $e_0$ & relative error in zeroth moment of volume \\ \hline
   $e_1$ & relative error in first moment of volume \\ \hline
   $e_2$ & relative error in second moment of volume \\ \hline   
   $\beta_0$ & functional weighting coefficient for zeroth moment of volume error \\ \hline
   $\beta_1$ & functional weighting coefficient for first moment of volume error \\ \hline
   $\beta_2$ & functional weighting coefficient for second moment of volume error \\ \hline 
   $\varepsilon$ & tolerance for minimization of functional $\mathcal{F}$ \\ \hline
   $\overline{\mathcal{F}}$ \rule{0mm}{4mm} & largest acceptable value of functional $\mathcal{F}$ \\ \hline        
\end{tabular}
\caption{List of variables for interface approximation}
\label{tab:surface}
\end{table}

\subsubsection{Interface Point and Normal Placement}

Once the parameters $d$, $\psi$, and $\theta$ are selected to fully define the surface that approximates the interface, a point location and outward normal are determined. The outward pointing normal is defined from the transformation of the $x$ axis to the $x'$ axis, i.e., the first column of matrix $\bm{R}$, and thus defined as such: $\bm{n} = -(\cos\psi\cos\theta,\text{\ }\sin\psi\cos\theta,\text{\ }-\sin\theta)$. With the origin at the center of sphere $\mathcal{D}$, the location of the interface normal is then simply $\mathbf{x}_p = -d\bm{n}$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Surface Reconstruction}
\label{Surface Reconstruction}

Surface reconstruction is the process of generating closed, manifold, polygonized surfaces from point clouds. The literature typically expects a dense, noisy population of points that come from laser-based scanners. The proposed algorithm does not in general produce a point cloud as dense as do laser scanners, but a brief review of surface reconstruction techniques is still informative.

Among the most well known surface reconstruction algorithms are the \textit{Power Crust} and \textit{Poisson surface reconstruction} techniques. Amenta \textit{et al.}~\cite{amenta_2001} present the \textit{Power Crust} algorithm for reconstructing watertight surfaces from unoriented point clouds. It approximates the medial axis transform from the point cloud, followed by an inverse transform to produce the medial axis and a piecewise-linear surface approximation. The algorithm does not perform well when the point set is not sufficiently dense, and performed quite poorly for point clouds generated from the algorithm described in the previous section. Kazhdan \textit{et al.} present \textit{Poisson surface reconstruction}~\cite{kazhdan_2008} and subsequently \textit{screened Poisson surface reconstruction}~\cite{kazhdan_2013} for oriented point clouds. They compute an indicator function defined as 1 at points inside the surface and 0 for points outside, whose gradient best approximates the vector field defined by the oriented point cloud. This amounts to solving a Poisson problem for an implicit indicator function, followed by application of marching cubes to polygonize the surface. The \textit{screened} approach provides a soft constraint that encourages the reconstructed isosurface to pass through the input points. In practice, the screened approach is significantly more robust than the original approach in terms of generating manifold surfaces from complex point clouds. The technique produces smooth surfaces that exhibit a resiliency to noise, outliers, and under-sampling that is superior to any other technique that has been experimented with.

Many other surface reconstruction approaches exist, including those making use of moving least squares, Delaunay and Voronoi constructions, and variational approaches~\cite{berger}. A novel Voronoi-based approach is presented as an alternative to these approaches that is tuned for the type of noise and point density from the point cloud generation algorithm in the previous section.

The proposed surface reconstruction technique relies on constructing a \textit{Voronoi diagram}, which for our purposes is a nearest neighbor partitioning of $\mathbb{R}^3$ based on a set of input \textit{Voronoi sites}. The desired output from a Voronoi partition is a mesh, namely a set of points, edges, facets, and cells (and their connectivities) that discretize space. Define a half plane $D(\bm{p},\bm{q})$ comprising all points $\bm{x}$ closer to site $\bm{p}$ than to site $\bm{q}$:
\begin{equation}
D(\bm{p},\bm{q}) = \{\bm{x} \mid d(\bm{p},\bm{x}) \leq d(\bm{q},\bm{x})\}
\end{equation}
where a distance function $d$ must be defined. Although there are instances of more exotic distance functions leading to modified Voronoi approaches, the Euclidean distance is associated with standard Voronoi diagrams. The \textit{Voronoi cell} $V(\bm{p})$ associated with site $\bm{p}$ is the set of points inside the intersection of all half planes involving site $\bm{p}$ and all other sites in the set of sites $\mathcal{P}$:
\begin{equation}
V(\bm{p}) = \bigcap \limits_{\bm{q} \in \mathcal{P}, \bm{q} \neq \bm{p}} D(\bm{p},\bm{q})
\end{equation}
A number of important properties exist for Voronoi partitions and its dual \textit{Delaunay tessellation}, but the one of most importance for these purposes is that the surface extracted from a set of Voronoi cells connected by shared facets is watertight and manifold. Several important considerations must be made in constructing a Voronoi partition, including handling degenerate and near-degenerate cases, the data schema and order of construction of the connected polytopes that comprise the partition, and the
performance of the algorithm. Refer to Aurenhammer~\cite{aurenhammer_1991} for a detailed survey of the mathematical and algorithmic approaches to Voronoi diagrams.

The proposed technique involves the following steps, to be described in turn:
\begin{itemize}[noitemsep]
\item Generate Voronoi site set from oriented point cloud and perform Voronoi partition of image
\item Define b-rep as the set of facets that share Voronoi sites with different material type, and perform cleanup on that surface
\item Decimate, or coarsen, the surface to a more tractable mesh resolution
\end{itemize}

\subsubsection{Voronoi Site Generation and Voronoi Partitioning}

Given the location of an interface point $\bm{x}_p$ and orientation of its corresponding normal $\bm{n}$, a pair of Voronoi sites are placed on either side of the point along the line of action of the normal, as shown in~\figref{vor4}. They are separated from the point by a distance $b$, and thus their locations are $\bm{x}_p \pm b \bm{n}$. The two Voronoi sites are assigned material types. For the two-material case that is considered here, the site corresponding to the position $\bm{x}_p - b\bm{n}$ is \textit{inside} $\Omega$, and thus is assigned material $m$. The site corresponding to the position $\bm{x}_p + b\bm{n}$ is \textit{outside} $\Omega$, and thus is assigned a void material. \textit{Voronoi partitioning} is performed using an implementation from \textit{Qhull}~\cite{barber_1996}, that is robust even for near-degenerate Voronoi site locations.

\subsubsection{Surface Extraction and Cleanup}

The b-rep is extracted from the Voronoi partition as the set of facets that share Voronoi sites of differing material types, and again, is guaranteed to be watertight and manifold. An additional step is performed, however, to mitigate undesired ``cross-talk'' facets caused by Voronoi partitioning of neighboring site pairs. ``Good facets'' are identified as those b-rep facets whose Voronoi sites belong to a site pair originating from the same point and normal, and ``bad facets'' are those b-rep facets whose Voronoi sites originate from different points in the point cloud. For surfaces with small curvature, the area of good facets significantly outweighs that of the bad facets. Nonetheless, the existence of bad facets causes a stair-stepping feature in the resulting surface that is unacceptable.

The artifact is addressed as follows: ``Bad edges'' are identified as those edges that share two bad facets. Networks of connected bad edges are identified, and each network is collapsed to one point (see \figref{cross1}). In the simplest case, for a surface with a small amount of curvature, no bad edges are connected and each is independently collapsed. Any good facet that is connected to a network of bad edges is modified to connect to the new collapsed point. The good facets are triangulated to maintain planarity following the removal of bad facets. This increases the data required to define the surface mesh, but the decimation step described in the next section resolves this issue immediately. The sequence is demonstrated on the full \textit{ex vivo} heart example in~\figref{cross2}.

\begin{figure}[ht]
\centering
\subfigure[]{%
		\includegraphics[scale=0.083]{media/2-shabaka/3-clean-zoom/1-init-zoom.png}
\label{fig:cross1-1}}		
\subfigure[]{%
		\includegraphics[scale=0.083]{media/2-shabaka/3-clean-zoom/2-badfacets-zoom.png}
\label{fig:cross1-2}}		
\subfigure[]{%
		\includegraphics[scale=0.083]{media/2-shabaka/3-clean-zoom/3-badsegs-zoom.png}		
\label{fig:cross1-3}}					
\subfigure[]{%
		\includegraphics[scale=0.083]{media/2-shabaka/3-clean-zoom/4-fine-zoom.png}
\label{fig:cross1-4}}				
%
\caption{Clean-up of undesirable ``cross-talk'' facets for a surface patch: (a) initial surface following Voronoi-based surface reconstruction, (b) identification of ``cross-talk'' facets, (c) identification of edges to be collapsed, (d) final cleaned surface.}
\label{fig:cross1}
\end{figure}

For the vast majority of bad edge networks, the collapse technique results in a smoother surface that remains closed and manifold. For regions of high-curvature, there a small set of cases in which this clean-up step may cause the surface to become non-manifold. The topology of particular networks of bad edges that cause this phenomenon are identified based on heuristics, and are not collapsed to preserve the manifold property. The current approach thus not only does not accurately capture regions of high curvature, but also is not able to alleviate the issue of ``cross-talk'' facets in regions of high curvature. Handling regions of curvature or even sharp corners and edges can certainly be handled, though. The technique would involve including additional templates in the interface approximation step that would allow more than two Voronoi sites to be generated for each sampling window. For example, three Voronoi sites can be used to produce an edge, and four sites can be used to produce a corner.

\begin{figure}[ht]
\centering
\subfigure[]{%
		\includegraphics[scale=0.07]{media/2-shabaka/4-clean/1-init.png}
\label{fig:cross2-1}}		
\subfigure[]{%
		\includegraphics[scale=0.07]{media/2-shabaka/4-clean/2-badfacets.png}
\label{fig:cross2-2}}		
\subfigure[]{%
		\includegraphics[scale=0.07]{media/2-shabaka/4-clean/3-badsegs.png}	
\label{fig:cross2-3}}						
\subfigure[]{%
		\includegraphics[scale=0.07]{media/2-shabaka/4-clean/4-fine.png}		
\label{fig:cross2-4}}		
%
\caption{Clean-up of undesirable ``cross-talk'' facets for surface of \textit{ex vivo} human heart: (a) initial surface following Voronoi-based surface reconstruction, (b) identification of ``cross-talk'' facets, (c) identification of edges to be collapsed, (d) final cleaned surface.}
\label{fig:cross2}
\end{figure}

\subsubsection{Surface Decimation}

Surface \textit{decimation} is performed to reduce the surface mesh to a practical size without significantly changing the geometry. The philosophy in image-based meshing, surface extraction, and surface reconstruction is typically to make use of as much information is available to construct a mesh of the highest fidelity possible, and only then to address the practical consideration of mesh resolution for simulation purposes. Indeed, this is what \textit{Simpleware}'s {+FE Free} module does as described previously. The challenge then becomes applying decimation in a manner that does not lose more features from the original surface than is desired. For the purposes of this algorithm, decimation is performed using the code \textit{ACVD}~\cite{valette_2004, valette_2008}, which clusters vertices and triangles of an input surface to generate a coarser surface mesh whose resulting triangles exhibit excellent aspect ratio. The code does not preserve sharp edges or corners. This is actually not necessarily an issue for biological structures as they tend not to have singularities, but would be a problem if the proposed image-based meshing paradigm were extended to meshing mechanical parts from micro-CT scans, for example.

\subsubsection{Results}

Results of the procedure described in this chapter are shown in~\figref{shabakaseq} for the \textit{ex vivo} heart example. The optimal parameters identified for robust surface generation across a variety of examples are shown in~\tabref{Mod5}. The algorithm was rigorously tested with these parameters to produce closed, manifold surfaces for a wide variety of examples.

\begin{table}[ht!]
 \centering
   \begin{tabular}{|c||c|c|}
   \hline 
   \textbf{Variable} & \textbf{Description} & \textbf{Value} \\ \hline \hline
   $R_{\mathcal{W}}$ & window radius (in voxels) & 5 \\ \hline
   $d_{\mathcal{W}}$ & sampling distance between adjacent windows (in voxels) & 2 \\ \hline
   \multirow{2}{*}{$\overline{k}_{\mathcal{M}}$ \rule{0mm}{4mm}} & threshold for acceptable ratio of voxels in & \multirow{2}{*}{0.925} \\
   {} & window $\mathcal{W}$ belonging to material $m$ & {} \\ \hline
   $\beta_0$ & functional weighting coefficient for zeroth moment of volume & 0.5 \\ \hline
   $\beta_1$ & functional weighting coefficient for first moment of volume & 0.3 \\ \hline   
   $\varepsilon$ & tolerance for minimization of functional $\mathcal{F}$ & $10^{-14}$ \rule{0mm}{4mm} \\ \hline
   $\overline{\mathcal{F}}$ \rule{0mm}{4mm} & largest acceptable value of functional $\mathcal{F}$ & $0.15$ \\ \hline
   \multirow{2}{*}{$b$} & distance between interface normal and & \multirow{2}{*}{$1.1$} \\
   {} & corresponding Voronoi site pair (in voxels) & {} \\ \hline
\end{tabular}
\caption{Optimal parameter values for b-rep generation}
\label{tab:Mod5}
\end{table}

\begin{figure}[ht!]
\centering
\subfigure[]{%
		\includegraphics[scale=0.092]{media/2-shabaka/2-surf/1-seg.png}
\label{fig:shabakaseq1}}
\subfigure[]{%
		\includegraphics[scale=0.092]{media/2-shabaka/2-surf/2-normals.png}
\label{fig:shabakaseq2}}
\subfigure[]{%
		\includegraphics[scale=0.092]{media/2-shabaka/2-surf/3-ptcloud.png}
\label{fig:shabakaseq3}}
\subfigure[]{%
		\includegraphics[scale=0.092]{media/2-shabaka/2-surf/4-finesurf.png}
\label{fig:shabakaseq4}}
\subfigure[]{%
		\includegraphics[scale=0.092]{media/2-shabaka/2-surf/5-surf.png}
\label{fig:shabakaseq5}}
%
\caption{(a) Segmented image, (b) point/normal placement, (c) oriented point cloud (normals not shown), c) cleaned surface mesh generated from Voronoi partition (edges not shown), and d) final decimated surface}
\label{fig:shabakaseq}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{File Formats}
\label{File Formats-SURF}

Among the simplest and most prevalent file formats for free software for storing point clouds and surface meshes are the Stanford Polygon Format (PLY)~\cite{ply} and the Visualization Toolkit Format (VTK)~\cite{vtk}. Similar to the file format of images and image masks, these formats include a header that describes the data that it precedes. The number of vertices is included in the header, as well as a list of expected point data in the file (e.g., spatial coordinates, normal components). Both file formats handle many different data types (again, \texttt{unsigned char}, \texttt{int}, etc.), so the data type of each piece of data must be prescribed as well. And again, if the data is stored in binary format, endianness must also be prescribed. The data itself simply includes vertex coordinates, additional vertex property data if available, and in the case of meshes, the vertex connectivity of facets.

Once again, the raw data may be stored in ASCII or binary format. ASCII format for these point clouds and surface meshes holds significantly more value for these data types than for images or image masks, as specific vertex coordinates and/or connectivities can be queried or even modified. However, for dense point clouds or fine meshes, file sizes can become intractable, and thus binary storage is still the preferred route. Newer editions of the VTK format store data as XML, but were not explored for the purposes of this work.

\section{Mesh Generation}
%
Provided an appropriate surface mesh, CAD-based meshing techniques seek to automatically generate an unstructured discretization of the enclosed volume. Under rare circumstances the topology of the object of interest may allow for a \textit{structured} mesh, in which there is a predictable repeated connectivity among neighboring elements, but to accommodate a surface of arbitrary form an \textit{unstructured} mesh is necessary. The challenge in automated meshing is to maximize the the element shape quality while minimizing computational cost or human intervention~\cite{blacker_2001}. The discussion will focus on generating meshes for simulations using the finite element method and its variants. For conventional finite element approaches, topological restrictions on the mesh elements make hexahedral and tetrahedral topologies the most popular choices. These approaches have had some success, but not without serious drawbacks. Polyhedral meshing is considered as an alternative, which would be used in conjunction with polyhedral finite element methods. Established meshing techniques are summarized, together with a demonstration of the advantages of the polyhedral approach.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Hexahedral Meshing}
\label{Hexahedral Meshing}

In general, hexahedral discretizations produce the most accurate solutions and more computationally efficient than its alternatives in finite element simulations~\cite{tautges_2001}, and thus hex elements are the preferred element of choice. To date, though, no algorithm exists that can perform automatic hexahedral meshing of surfaces having arbitrary geometry and topology. The difficulty lies in the strict nodal connectivity requirements that constrain the hex mesh structure to consist of either stacks of elements or closed loops~\cite{young_2008}. 

Among the most popular classes of hexahedral meshing techniques are: \textit{primitives}, \textit{overlay grid}, and \textit{automated decomposition}~\cite{blacker_2001}. \textit{Primitives} typically involve producing a 2D unstructured quad mesh of a cross section, followed by \textit{sweeping} the constant topology cross section. This approach of course is limited to topologies involving a swept cross-section.\textit{Overlay grids} produce a structured background grid, and cut elements and/or modify vertices so that the hex elements conform to the original surface. This approach can lead to elements near the surface of potentially very poor quality, however. \textit{Automated decomposition} techniques attempt to decompose the volume into separate parts, usually in the form of primitive shapes or swept volumes. These approaches suffer from difficulty in matching meshes at part interfaces and requiring potentially significant de-featuring of the surface.

Hexahedral meshing algorithms typically only apply to a limited set of geometries. In practice, human intervention is necessary to decompose the geometry according to the algorithms available, adjust the geometry as needed to accommodate those algorithms, and - much like image segmentation - potentially select between a suite tools to be employed as needed~\cite{blacker_2001}. These manual efforts can become impracticably time consuming or even impossible for surfaces of biological tissues, and thus hexahedral meshes tend to lose out to tetrahedral meshes for biomechanics applications.

Mixed element approaches attempt to alleviate the difficulty of producing fully hexahedral meshes by only requiring the mesh to be \textit{hex dominant}. Namely, the majority of elements are hexahedra, tetrahedra exist where a hexahedral mesh is intractable, and pyramid elements are required in the transitional layers. These techniques tend to either: be \textit{indirect} in that their focus is on converting an already existing tetrahedral mesh to a hex-dominant mesh by combining hexahedral elements~\cite{baudouin_2014, gao_2017}; attempt to honor the surface with tetrahedral elements together with an octree hexahedral representation in the interior of the volume~\cite{young_2008, lobos_2015}; or exhibit tetrahedral elements toward the interior of the volume where frontal approaches of purely hex meshes fail~\cite{blacker_2001}. These approaches have shown promise in meshing arbitrary domains, but little work has been done in evaluating the accuracy and performance of such approaches in a finite element setting in comparison to fully hex or fully tet meshes~\cite{tautges_2001}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Tetrahedral Meshing}
\label{Tetrahedral Meshing}

The two most widely adopted approaches for automated unstructured tetrahedral mesh generation are \textit{advancing front} and \textit{Delaunay tetrahedralization}~\cite{lohner_1997}. In advancing front techniques~\cite{jin_1993, lohner_1988}, elements are inserted one at a time, starting from the initial triangular surface mesh and working toward the interior of the enclosed volume. Care must be taken to avoid poor element quality when the front collides from different directions. The success of the approach depends on the initial quality and size of the triangular surface mesh, which can be remedied by surface remeshing/decimation.

Delaunay tetrahedralization is the dual of the previously described \textit{Voronoi diagram}. Namely, the Voronoi sites form the vertices of the Delaunay tetrahedralization, whose edges perpendicularly pass through the coresponding Voronoi facets. The set of tetrahedra satisfy the property that no other vertex is contained within the circumsphere formed by the vertices of each tetrahedron. The Delaunay tetrahedralization is typically constructed incrementally. A tetrahedralization is carried out on an initial point distribution. Additional points are introduced and tetrahedra encompassing the new point are removed. The void created by the deletion of these tetrahedra is then remeshed~\cite{young_2008}. The specification of the initial point distribution and subsequent insertion of points is dictates the resulting quality of the mesh elements. Constraining the Delaunay tetrahedralization to adhere to the input surface can also severely affect element quality and even produce sliver elements~\cite{lohner_1997}.

A Delaunay meshing implementation from \textit{Tetgen}~\cite{tetgen} is utilized to interact with the Shabaka code to generate high quality tetrahedral meshes of linear or quadratic order. The Tetgen code is constrained to honor the surface mesh generated by Shabaka exactly. A tetrahedral mesh of only the ventricles of the \textit{ex vivo} heart example is shown in \figref{tetmesh}.
\begin{figure}[htbp!]
\centering
\subfigure[]{%
		\includegraphics[scale=0.14]{media/4-cardioid/0-ventriclesurf.png}
\label{fig:tet1}}
\subfigure[]{%
		\includegraphics[scale=0.14]{media/4-cardioid/1-tet.png}
\label{fig:tet2}}
%
\caption{Bi-ventricular mesh of \textit{ex vivo} human heart: (a) surface mesh, and (b) clipped view of quadratic tetrahedral mesh used in simulations}
\label{fig:tetmesh}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Polyhedral Meshing}
\label{Polyhedral Meshing}

Although hexahedral meshes are generally preferred for conventional finite element approaches, to date there are no techniques available that offer a robust automatic pipeline to generate hex meshes. Thus, tetrahedral mesh generation tools are typically the de facto choice for image-based meshing. Linear tet elements can only represent a constant strain, however, leading to inaccurate solution approximation unless impractically fine meshes are used. Genearlly speaking, linear tets are not to be used for solid mechanics problems involving near-incompressibility~\cite{hughes_2007}, tension, torsion, bending~\cite{wang_2004, benzley_1995}, or contact~\cite{maas_2016}. Quadratic tets, on the other hand, produce much more accurate results are generally the most popular element choice for biological applications. For problems involving complex geometries and/or requiring high fidelity solutions, the resulting problem size for quadratic tet meshes can be problematic. Polyhedral meshes, in conjunction with polyhedral finite element methods, attempt to compete with the robustness of tetrahedral meshes and the resulting accuracy and computational efficiency that result from hexahedral meshes.

Polyhedral meshing approaches tend to fall under two categories: those that seek to produce a Voronoi partition of the domain, and those that seek a hex-dominant mesh. Meshing techniques that seek to generate Voronoi partitions~\cite{garimella_2014, lee_2015} enjoy the advantage of exclusively convex elements with desirable aspect ratio. However, this comes at the price of needing to remesh the surface, which re-opens the conversation regarding feature-preservation. Indeed, Ebeida \textit{et al.}~\cite{ebeida_2011, mitchell_2015} for example, strategically sample the input surface mesh before reconstructing it. Special care must be taken to sample regions of high curvature and sharp corners, and are not well preserved for some of the examples shown in their work. Additionally, for more general CAD-based meshing applications, even if all features honored exactly, it may still be desirable to the preserve the input surface mesh without modification when creating a volume mesh, for the purposes of applying boundary conditions or mating adjacent parts.

Hex-dominant polyhedral meshing ``sculpts'' a background hex mesh with the input b-rep, producing hexahedra on the interior and arbitrary polyhedral shapes near the surface (see ~\figref{cel5} and~\figref{zoom}. These arbitrary polyhedra must be accommodated by an element formulation that deviates from the conventional FEM approach, to be discussed in~\chapref{4}.
\begin{figure}[htbp!]
\centering
\subfigure[]{%
		\includegraphics[scale=0.18]{media/3-celeris/1-brep.png}
\label{fig:cel1}}		
\subfigure[]{%
		\includegraphics[scale=0.18]{media/3-celeris/2-hex.png}
\label{fig:cel2}}		
\subfigure[]{%
		\includegraphics[scale=0.18]{media/3-celeris/3-pmesh.png}
\label{fig:cel3}}		
\subfigure[]{%
		\includegraphics[scale=0.18]{media/3-celeris/4-clip.png}
\label{fig:cel4}}	
\subfigure[]{%
		\includegraphics[scale=0.18]{media/3-celeris/5-color.png}
\label{fig:cel5}}			
\caption{Generation of polyhedral mesh: (a) input surface mesh, (b) bounding hex mesh,  (c) resulting polyhedral mesh, (d) clipped mesh, and (e) highlight of elements with cuboidal vs. general polyhedral shape.}
\label{fig:cel}
\end{figure}
\begin{figure}[htbp!]
\centering
\subfigure[]{%
		\includegraphics[scale=0.125]{media/3-celeris/zoom/zoom1.png}
\label{fig:zoom1}}		
\subfigure[]{%
		\includegraphics[scale=0.125]{media/3-celeris/zoom/zoom2.png}
\label{fig:zoom2}}		
\subfigure[]{%
		\includegraphics[scale=0.125]{media/3-celeris/zoom/zoom3.png}
\label{fig:zoom3}}		
\subfigure[]{%
		\includegraphics[scale=0.125]{media/3-celeris/zoom/zoom4.png}
\label{fig:zoom4}}	
\subfigure[]{%
		\includegraphics[scale=0.125]{media/3-celeris/zoom/zoom5.png}
\label{fig:zoom5}}		
\subfigure[]{%
		\includegraphics[scale=0.125]{media/3-celeris/zoom/zoom6.png}
\label{fig:zoom6}}	
\caption{Three example arbitrary polyhedral elements presented at different angles}
\label{fig:zoom}
\end{figure}

This scuplting approach must handle geometric near-degeneracies in a robust way. An implementation of such an approach in the polyhedral FEM software ~\cite{Celeris} is used to generate polyhedral meshes from surfaces generated by Shabaka~\cite{rashid_2013}.
DESCRIPTION OF RASHID APPROACH

As it pertains to image-based modeling and simulation, the greatest benefit that polyhedral approaches offer is a separation between the \textit{simulation resolution} and the \textit{geometric resolution}. More detail will come in ~\chapref{4} regarding the polyhedral element formulation, but for this discussion the key is that nodal degrees of freedom are only defined at the points of the background mesh, independent of the input b-rep. Thus, one can simultaneously retain a high fidelity description of a surface while only running a simulation to the simulation resolution that is required. For the other meshing approaches described in this chapter, the volume mesh resolution is implicitly constrained by the input surface mesh resolution. For complex geometries found in biological tissues, the surface mesh resolution is almost always sacrificed to avoid a problematic number of degrees of freedom in the subsequent finite element solution.

Given a bi-ventricular surface mesh of the \textit{ex vivo} human heart example generated by Shabaka, volume meshes are compared between linear polyhedral elements and quadratic tetrahedral elements (it will be shown in ~\chapref{4} that linear polyhedral elements behave and perform like linear hexahedra, and are sufficient for generating accurate solutions). The sculpt routine in Celeris, Delaunay tetrahedralization routine in Tetgen, and advancing front routine in Simpleware were applied to the same surface mesh resolution with 50k points, and the same desired maximum element volume of 2 $mm^3$. Indeed, ~\figref{comp} shows that the polyhedral approach reduces the system size by a factor of 2 or more. The reduction in system size stems first from the fact that the polyhedral elements are lower order compared to the tetrahedral elements, and second from not requiring an unnecessarily large number of nodes and elements near the surface to accommodate the large number of surface points. It should be emphasized that even at this surface resolution, a noticeable degree of geometric features are sacrificed. The greater the importance of geometric fidelity, the greater the value the polyhedral approach offers.

\begin{figure}[ht!]
\centering
		\includegraphics[scale=0.2]{media/comparison.png}
%\subfigure[]{%
%		\includegraphics[scale=0.15]{media/3-celeris/8-celeris.png}
%\label{fig:comp-1}}		
%\subfigure[]{%
%		\includegraphics[scale=0.15]{media/3-celeris/9-cardioid.png}		
%\label{fig:comp-2}}	
%\subfigure[]{%
%		\includegraphics[scale=0.15]{media/3-celeris/10-simpleware.png}
%\label{fig:comp-3}}				
%
\caption{Comparison of meshes between: linear polyhedral mesh from Celeris, quadratic tetrahedral mesh from Tetgen, and quadratic tetrahedral mesh from Simpleware. Note Simpleware focuses on generating high quality elements, hence the larger number of DOF compared to Tetgen.}
\label{fig:comp}
\end{figure}

The entire workflow from image to image mask to b-rep to polyhedral mesh is demonstrated in ~\figref{celsuite} for \textit{ex vivo} canine and human hearts from the CardioVascular Research Grid~\cite{cvgg}.

\begin{figure}[htbp!]
\centering
\includegraphics[width=1.0\textwidth]{media/3-celeris/7-suite.png}
\caption{Suite of polyhedral finite element meshes generated from image data \vspace{1cm}}
\label{fig:celsuite}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{File Formats}
\label{File Formats-MESH}
File formats for volume meshes follow the same paradigm as for point clouds and surface meshes. Namely, spatial coordinates of points are listed, followed by a list of elements, defined based on connectivities of those points. The tetrahedral meshes generated by Shabaka are stored in VTK format or Abaqus~\cite{abaqus} INP format. Polyhedral meshes are stored in a similar manner, but each element additionally requires a listing of facet data to accommodate arbitrary polyhedral topology. For the purposes of running simulations, additional information may be included with the mesh, such as surface or point sets for the purposes of assigning boundary conditions.

\section{Shabaka: A Free Image-Based Meshing Tool}

The image-based meshing steps described in this chapter are assembled to form a novel image-based meshing tool \textit{Shabaka}~\cite{shab}, available on GitHub at~\url{github.com/omhafez/shabaka}. A screenshot of the repository on GitHub is shown in~\figref{github}.
\begin{figure}[ht!]
\centering
\vspace{2.5mm}
\includegraphics[width=1.0\textwidth]{media/2-shabaka/2-surf/7-shabaka.png}
\caption{Screenshot of Github repo}
\label{fig:github}
\end{figure}
Simple instructions are available to install the code on Linux, Mac, or Windows in about 15 minutes. A build script compiles the code and downloads library dependencies including: \textit{NRRD}~\cite{nrrd} for image mask I/O, \textit{NLopt}~\cite{nlo} for nonlinear optimization, \textit{Qhull}~\cite{barber_1996} for Voronoi partitioning, \textit{ACVD}~\cite{valette_2004} for surface decimation, and \textit{Meshlab}~\cite{meshlab} and \textit{Gmsh}~\cite{geuzaine_2009} for miscellaneous mesh tasks. Libraries are gathered from the standard APT package manager on Ubuntu and from \textit{Homebrew}~\cite{brew} on Mac. The Windows installation makes use the \textit{Windows Subsystem for Linux (WSL)}, so installation is treated in the same manner as for Ubuntu. Simple unit tests are made available to verify a successful installation and the utility of various components of the code.

Additional free software packages are included in the build to provide an end-to-end image-based meshing pipeline. Namely, \textit{Seg3D}~\cite{Seg3D} is included for image processing and image segmentation functionality, \textit{Tetgen}~\cite{tetgen} for tetrahedral meshing, and \textit{ParaView}~\cite{paraview} for visualization. Following a full installation of the code, the user can: process and segment a medical image in Seg3D to produce an image mask, produce a high quality surface mesh with Shabaka, produce a tetrahedral mesh in VTK or Abaqus INP format using Tetgen, and visualize the resulting mesh in ParaView. Documentation on how to efficiently segment images in Seg3D has been written and included in the GitHub repo, along with essential publications related to steps in the workflow. The tool is catered toward users of simulation, rapid prototyping, or visualization software. No prior knowledge or understanding of image segmentation, mesh generation, or UNIX is required.

The core code for Shabaka is written in C++ and Fortran, along with Python driver scripts to facilitate the interaction between different portions of the code and with external packages. After processing command-line inputs, the code reads the input image mask in NRRD format. The code automatically resamples segmented images that do not exhibit isotropic voxel spacing, so that the point cloud generation step may assume every input image mask has equal spacing in all three directions. The point cloud generation step is easily parallelized since interfaces are approximated for each window independently of one another. The final oriented point cloud is exported in PLY format. Voronoi site locations are generated and are used to call Qhull to generate a Voronoi partition. The surface mesh is extracted from the Qhull output, and is subsequently cleaned and decimated. The final surface is exported in both PLY and STL formats.

The code has a simple command-line interface in a UNIX environment that offers a number of command-line options. Some of the options include the ability to specify a desired mesh resolution, and whether to automatically call Tetgen to produce a tetrahedral mesh from the surface generated from Shabaka. The option is also available to call the Meshlab implementation of screened Poisson surface reconstruction as an alternative to the default Voronoi-based surface reconstruction technique. Resulting surface meshes from screened Poisson surface reconstruction tend to be over-smoothed compared to those from the Voronoi-based approach, but the implementation in Meshlab performs impressively fast, and tends to be more robust for particularly challenging surfaces, where in rare cases Voronoi approach fails to produce a closed, manifold surface.

Shabaka is currently limited to meshing binary image masks. It can mesh multiple disjoint objects in a single image, but cannot currently produce meshes from multi-label masks. Each surface is watertight and manifold, and no manual correction of the mesh is required. A surface produced from Shabaka may be used as input to any software that accepts a surface mesh as input. As it pertains to the focus of this discussion, the surface mesh is inserted into a mesh generation tool, be it Tetgen for creating a tetrahedral mesh, or Celeris for creating a polyhedral one. The surface generation step typically takes less than 5 minutes for realistic input image masks using a 2.4 GHz Intel Core i7 processor with 16 GB of RAM. In all, if the user has an image mask readily available, he or she can install Shabaka and generate a high quality surface mesh and subsequent volume mesh in less than half an hour on a typical laptop.

Shabaka has been rigorously tested against a wide variety of input images. Image masks have been meshed for the heart, brain, lungs, liver, skull, pelvis, vertebra, femur, and portions of the knee joint (see \figref{showcase}).

\begin{figure}[ht!]
\centering
\vspace{2.5mm}
\includegraphics[width=1.0\textwidth]{media/2-shabaka/2-surf/6-showcase.png}
\caption{Suite of example surfaces generated from image data}
\label{fig:showcase}
\end{figure}
